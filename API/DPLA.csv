Title, Publisher, Description, Date
Exploratory Advanced Research Program : the role of artificial intelligence and machine learning in federally supported surface transportation initiatives,[Washington  D.C.] : U.S. Department of Transportation  Federal Highway Administration,Description based on online resource  PDF version; title from cover (FHWA  viewed May 17  2019).,2020-02-03T16:51:10.618Z
Learning by experimentation,Alexandria  VA : U.S. Army Research Institute for the Behavioral and Social Sciences,Description based on online resource; title from PDF cover (DTIC  viewed May 11  2017).,2020-02-03T16:51:10.618Z
Individual differences in hemispheric specialization,Alexandria  VA : U.S. Army Research Institute for the Behavioral and Social Sciences,Description based on online resource; title from PDF cover (DTIC  viewed May 11  2017).,2020-02-03T16:51:10.618Z
Digital decision-making : the building blocks of machine learning and artificial intelligence : hearing before the Subcommittee on Communications  Technology  Innovation  and the Internet of the Committee on Commerce  Science  and Transportation  United States Senate  One Hundred Fifteenth Congress  first session  December 12  2017,Washington : U.S. Government Publishing Office,Description based on online resource; title from PDF title screen (govinfo web site  viewed on Sept. 17  2019).,2020-02-03T16:51:10.618Z
A Model-Based AI-Driven Test Generation System,Washington : U.S. Government Publishing Office,Achieving high software quality today involves manual analysis  test planning  documentation of testing strategy and test cases  and development of automated test scripts to support regression testing. This thesis is motivated by the opportunity to bridge the gap between current test automation and true test automation by investigating learning-based solutions to software testing. We present an approach that combines a trainable web component classifier  a test case description language  and a trainable test generation and execution system that can learn to generate new test cases. Training data was collected and hand-labeled across 7 systems  95 web pages  and 17 360 elements. A total of 250 test flows were also manually hand-crafted for training purposes. Various machine learning algorithms were evaluated. Results showed that Random Forest classifiers performed well on several web component classification problems. In addition  Long Short-Term Memory neural networks were able to model and generate new valid test flows.,2020-04-09T17:48:20.138Z
Identifying Outputs of Generative Adversarial Networks Act : report (to accompany H.R. 4355) (including cost estimate of the Congressional Budget Office),[Washington  D.C.] : [U.S. Government Publishing Office],Description based on online resource; title from PDF caption (Govinfo website  viewed Nov. 6  2019).,2020-02-03T16:51:10.618Z
Learning Data-Driven Models of Non-Verbal Behaviors for Building Rapport Using an Intelligent Virtual Agent,[Washington  D.C.] : [U.S. Government Publishing Office],There is a growing societal need to address the increasing prevalence of behavioral health issues  such as obesity  alcohol or drug use  and general lack of treatment adherence for a variety of health problems. The statistics  worldwide and in the USA  are daunting. Excessive alcohol use is the third leading preventable cause of death in the United States (with 79 000 deaths annually)  and is responsible for a wide range of health and social problems. On the positive side though  these behavioral health issues (and associated possible diseases) can often be prevented with relatively simple lifestyle changes  such as losing weight with a diet and/or physical exercise  or learning how to reduce alcohol consumption. Medicine has therefore started to move toward finding ways of preventively promoting wellness  rather than solely treating already established illness. Evidence-based patient-centered Brief Motivational Interviewing (BMI) interven- tions have been found particularly effective in helping people find intrinsic motivation to change problem behaviors after short counseling sessions  and to maintain healthy lifestyles over the long-term. Lack of locally available personnel well-trained in BMI  however  often limits access to successful interventions for people in need. To fill this accessibility gap  Computer-Based Interventions (CBIs) have started to emerge. Success of the CBIs  however  critically relies on insuring engagement and retention of CBI users so that they remain motivated to use these systems and come back to use them over the long term as necessary. Because of their text-only interfaces  current CBIs can therefore only express limited empathy and rapport  which are the most important factors of health interventions. Fortunately  in the last decade  computer science research has progressed in the design of simulated human characters with anthropomorphic communicative abilities. Virtual characters interact using humans’ innate communication modalities  such as facial expressions  body language  speech  and natural language understanding. By advancing research in Artificial Intelligence (AI)  we can improve the ability of artificial agents to help us solve CBI problems. To facilitate successful communication and social interaction between artificial agents and human partners  it is essential that aspects of human social behavior  especially empathy and rapport  be considered when designing human-computer interfaces. Hence  the goal of the present dissertation is to provide a computational model of rapport to enhance an artificial agent’s social behavior  and to provide an experimental tool for the psychological theories shaping the model. Parts of this thesis were already published in [LYL+12  AYL12  AL13  ALYR13  LAYR13  YALR13  ALY14].,2020-04-09T17:48:20.138Z
Savage Diction,[Washington  D.C.] : [U.S. Government Publishing Office],Our technology plays a crucial role in defining the human landscape. Far from simple tools  the computational systems that exist today are intelligent and globally networked. This affects the narration we construct of ourselves and the world we live in. If language is the process of transmitting information from one mind to another  this transmission is manifested in a complex recursive entanglement of communication transcribed by our media and technology. Savage Diction is a short film narrated by artificial intelligence. It is a curated collection of media artifacts  narrated by an intelligent computational system. This narration is generated by machine learning  a subdomain of artificial intelligence  through the process of object recognition and natural language processing. Different interpretations are algorithmically generated by training the machine learning models on separate databases of textual artifacts and range from released Hilary Clinton emails to a corpus of romance novels. By interjecting these narratives into the film  a visual investigation is created. One that embodies the significance of data used to train intelligent systems  the contextual associations that emerge from the process of intelligent algorithms  and the shifting definition of culture that results when artificial intelligence becomes a key producer of cultural artifacts.,2020-02-19T18:54:41.375Z
Integration of graphical  physics-based  and machine learning methods for assessment of impact and recovery of the built environment from wind hazards,[Washington  D.C.] : [U.S. Government Publishing Office],2019 Summer. Includes bibliographical references. The interaction between a natural hazard and a community has the potential to result in a natural disaster with substantial socio-economic losses. In order to minimize disaster impacts  researchers have been improving building codes and exploring further concepts of community resilience. Community resilience refers to a community's ability to absorb a hazard (minimize impacts) and "bounce back" afterwards (quick recovery time). Therefore  the two main components in modeling resilience are: the initial impact and subsequent recovery time. With respect to a community's building stock  this entails the building damage state sustained and how long it takes to repair and reoccupy that building. In modeling these concepts  probabilistic and physics-based methods have been the traditional approach. With advancements in artificial intelligence and machine learning  as well as data availability  it may be possible to model impact and recovery differently. Most current methods are highly constrained by their topic area  for example a damage state focuses on structural loading and resistance  while social vulnerability independently focus on certain social demographics. These models currently perform independently and are then aggregated together  but with the complex connectivity available through machine learning  structural and social characteristics may be combined simultaneously in one network model. The popularity of machine learning predictive modeling across multiple different applications has risen due to the benefit of modeling complex networks and perhaps identifying critical variables that were previously unknown  or the mechanism behind how these variables interacted within the predictive problem being modeled. The research presented herein outlines a method of using artificial neural networks to model building damage and recovery times. The incorporation of graph theory to analyze the resulting models also provides insight into the "black box" of artificial intelligence and the interaction of socio-technical parameters within the concept of community resilience. The subsequent neural network models are then verified through hindcasting the 2011 Joplin tornado for individual building damage and the time it took to repair and reoccupy each building. The results of this research show viability for using these methods to model damage  but more research work may be needed to model recovery at the same level of accuracy as damage. It is therefore recommended that artificial neural networks be primarily used for problems where the variables are well known but their interactions are not as easily understood or modeled. The graphical analysis also reveals an importance of social parameters across all points in the resilience process  while the structural components remain mostly important in determining the initial impact. Final importance factors are determined for each of the variables evaluated herein. It is suggested moving forward  that modeling approaches consider integrating how a community interacts with its infrastructure  since the human components are what make a natural hazard a disaster  and tracing artificial neural network connections may provide a starting point for such integration into current traditional modeling approaches. (Doctor of Philosophy (Ph.D.)  Civil and Environmental Engineering  Colorado State University.),2020-04-06T15:57:41.483Z
Amara,[Washington  D.C.] : [U.S. Government Publishing Office],Designer's statement: The Amara reimagines the scope of relationships between humanity and its technological creations. What are the implications of wearing nonhuman technology on your body? This question relates to the urgency of biological crisis. As humans  we are inextricably linked to the destruction of our environment and the danger of annihilating our own species. With developments like artificial intelligence  the uncanny valley  and deep machine learning  we face moral dilemmas so cataclysmic that traditional design practices can offer us little in the way of preparation. This project explores design through the lens of dark optimism and object oriented ontology. Within the context of the human body and technologies that augment its function  the Amara presents a new paradigm of human / non-human interaction. One that strengthens my notion that accepting that our world exists for purposes beyond human pursuits is vital to our own survival.,2020-02-19T18:54:41.375Z
Optimal reservoir operations for riverine water quality improvement: a reinforcement learning strategy,[Washington  D.C.] : [U.S. Government Publishing Office],2011 Spring. Includes bibliographical references. Complex water resources systems often involve a wide variety of competing objectives and purposes  including the improvement of water quality downstream of reservoirs. An increased focus on downstream water quality considerations in the operating strategies for reservoirs has given impetus to the need for tools to assist water resource managers in developing strategies for release of water for downstream water quality improvement  while considering other important project purposes. This study applies an artificial intelligence methodology known as reinforcement learning to the operation of reservoir systems for water quality enhancement through augmentation of instream flow. Reinforcement learning is a methodology that employs the concepts of agent control and evaluative feedback to develop improved reservoir operating strategies through direct interaction with a simulated river and reservoir environment driven by stochastic hydrology. Reinforcement learning methods have advantages over other more traditional stochastic optimization methods through implicit learning of the underlying stochastic structure through interaction with the simulated environment  rather than requiring a priori specification of probabilistic models. Reinforcement learning can also be coupled with various computing efficiency techniques as well as other machine learning methods such as artificial neural networks to mitigate the "curse of dimensionality" that is common to many optimization methodologies for solving sequential decision problems. A generalized mechanism is developed  tested  and evaluated for providing near-real time operational support to suggest releases of water from upstream reservoirs to improve water quality within a river using releases specifically designated for that purpose. The algorithm is designed to address a variable number of water quality constituents  with additional flexibility for adding new water quality requirements and learning updated operating strategies in a non-stationary environment. The generalized reinforcement learning algorithm is applied to the Truckee River in California and Nevada as a case study  where the federal and local governments are purchasing water rights for the purpose of augmenting Truckee River flows to improve water quality. Water associated with those acquired rights can be stored in upstream reservoirs on the Truckee River until needed for prevention of water quality standard violations in the lower reaches of the river. This study shows that in order for the water acquired for flow augmentation to be fully utilized as a part of a longer-term strategy for water quality management  increased flexibility is required as to how those waters are stored and how well the storage is protected from displacement through reservoir spill during times of high runoff. The results show that with those flexibilities  the reinforcement learning mechanism has the ability to produce both short-term and long-term strategies for the use of the water  with the long-term strategies capable of significantly improving water quality during times of drought over current and historic operating practices. The study also evaluates a number of variations and options for the application of reinforcement learning methods  as well as use of artificial neural networks for function generalization and approximation. (Doctor of Philosophy (Ph.D.)  Civil and Environmental Engineering  Colorado State University.),2020-04-06T15:57:41.483Z
Intelligent Data Mining Techniques for Automatic Service Management,[Washington  D.C.] : [U.S. Government Publishing Office],Today  as more and more industries are involved in the artificial intelligence era  all business enterprises constantly explore innovative ways to expand their outreach and fulfill the high requirements from customers  with the purpose of gaining a competitive advantage in the marketplace. However  the success of a business highly relies on its IT service. Value-creating activities of a business cannot be accomplished without solid and continuous delivery of IT services especially in the increasingly intricate and specialized world. Driven by both the growing complexity of IT environments and rapidly changing business needs  service providers are urgently seeking intelligent data mining and machine learning techniques to build a cognitive ``brain" in IT service management  capable of automatically understanding  reasoning and learning from operational data collected from human engineers and virtual engineers during the IT service maintenance. The ultimate goal of IT service management optimization is to maximize the automation of IT routine procedures such as problem detection  determination  and resolution. However  to fully automate the entire IT routine procedure is still a challenging task without any human intervention. In the real IT system  both the step-wise resolution descriptions and scripted resolutions are often logged with their corresponding problematic incidents  which typically contain abundant valuable human domain knowledge. Hence  modeling  gathering and utilizing the domain knowledge from IT system maintenance logs act as an extremely crucial role in IT service management optimization. To optimize the IT service management from the perspective of intelligent data mining techniques  three research directions are identified and considered to be greatly helpful for automatic service management: (1) efficiently extract and organize the domain knowledge from IT system maintenance logs,2020-04-09T17:48:20.138Z
Automatic Extraction of Narrative Structure from Long Form Text,[Washington  D.C.] : [U.S. Government Publishing Office],Automatic understanding of stories is a long-time goal of artificial intelligence and natural language processing research communities. Stories literally explain the human experience. Understanding our stories promotes the understanding of both individuals and groups of people,2020-04-09T17:48:20.138Z
