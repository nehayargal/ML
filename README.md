# ğŸ§  Machine Learning & Applied AI Portfolio

A curated collection of real-world Machine Learning, NLP, Web Scraping, and Data Analysis projects.

This repository demonstrates hands-on experience across:

- Exploratory Data Analysis (Tabular + Text)
- NLP Pipelines
- API Development
- Web Scraping & Data Collection
- Feature Engineering
- Practical ML Workflow Design

---

## ğŸ“Œ Repository Overview

| Module | Description | Key Skills |
|--------|-------------|------------|
| ğŸ“Š EDA-Tabular (IRS dataset) | Data exploration, statistical analysis, feature engineering | Pandas, NumPy, Data Visualization |
| ğŸ“ EDA-Text | NLP preprocessing and text analysis | Tokenization, TF-IDF, Text Cleaning |
| ğŸ“° RSS | RSS feed parsing and automation | Data ingestion pipelines |
| ğŸ•·ï¸ Scrapy | Structured web scraping projects | Scrapy, Data extraction |
| ğŸŒ Web Scraping | Python-based scraping workflows | BeautifulSoup, Requests |
| ğŸ”Œ API | API-based ML/data workflows | REST APIs, Data serving |

---

## ğŸš€ Highlights

### 1ï¸âƒ£ End-to-End ML Workflow Experience
Each project demonstrates:
- Data acquisition
- Cleaning & preprocessing
- Feature engineering
- Analysis & insights generation
- Code modularity & reproducibility

---

### 2ï¸âƒ£ Real-World Data Engineering Exposure

Includes:
- Automated scraping pipelines
- Structured data ingestion
- Text normalization workflows
- Dataset transformation for modeling

---

### 3ï¸âƒ£ NLP & Text Processing Foundations

Applied techniques:
- Tokenization
- Stopword removal
- Text vectorization (TF-IDF)
- Basic NLP analytics

---

### 4ï¸âƒ£ API & Integration Skills

- Building and consuming APIs
- Structuring ML outputs
- Integrating data pipelines with external services

---

## ğŸ› ï¸ Tech Stack

- Python
- Pandas / NumPy
- Matplotlib / Seaborn
- Scikit-learn
- BeautifulSoup
- Scrapy
- REST APIs
- Jupyter Notebook

---

## ğŸ“‚ Repository Structure

